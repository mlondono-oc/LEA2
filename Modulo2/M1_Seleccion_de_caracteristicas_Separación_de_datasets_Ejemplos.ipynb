{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fPbcLP73CRW"
      },
      "source": [
        "# Selección de Características - Machine Learning\n",
        "\n",
        "La selección de características es el proceso de elegir un subconjunto de las variables más importantes mientras se intenta retener la mayor cantidad de información posible\n",
        "\n",
        "Veamos algunos métodos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FwCBvOP4dhs"
      },
      "source": [
        "## Métodos de filtrado\n",
        "\n",
        "info dataset pima-indians-diabetes: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq0GWX6ud--y",
        "outputId": "dd99f5a4-acb7-4723-d083-0bac8ad648d1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df_classification = pd.read_csv(url, names=names)\n",
        "print(df_classification.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MkKwy36mgum6",
        "outputId": "4a4f12aa-179f-4278-9ba1-93996bd0e084"
      },
      "outputs": [],
      "source": [
        "df_classification.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_Id4dS5ggzc"
      },
      "outputs": [],
      "source": [
        "# Separación de caracteristicas y target\n",
        "X_class = df_classification.drop(['class'], axis=1)\n",
        "y_class = df_classification['class']\n",
        "\n",
        "print(X_class.shape)\n",
        "print(y_class.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7USy6uAfjXc"
      },
      "source": [
        "### Variance Threshold\n",
        "\n",
        "Elimina todas las características cuya varianza no alcanza algún umbral. De forma predeterminada, elimina todas las características de varianza cero, es decir, las características que tienen el mismo valor en todas las muestras.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Q8Y1hTLkgiJG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "#Función de filtro de caracteristicas\n",
        "def variance_threshold(X,th):\n",
        "    var_thres=VarianceThreshold(threshold=th)\n",
        "    var_thres.fit(X)\n",
        "    new_cols = var_thres.get_support()\n",
        "    return new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SExVS7chiY_t",
        "outputId": "33c70830-ecf0-4ed1-df62-017c97fd396f"
      },
      "outputs": [],
      "source": [
        "# Obtener columnas seleccionadas\n",
        "X_new_class = variance_threshold(X_class, 0.20)\n",
        "# Nuevo dataframe\n",
        "df_classification_new = X_class.iloc[:,X_new_class]\n",
        "df_classification_new.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP2ile9qgSUv"
      },
      "source": [
        "### SelectKBest\n",
        "\n",
        "Selección de características de acuerdo con las k puntuaciones más altas. Utiliza una función que toma dos matrices X e y, y devuelve un par de matrices (puntuaciones, valores de p) o una única matriz con puntuaciones.\n",
        "\n",
        "La función predeterminada solo funciona con tareas de clasificación (f_classif - ANOVA).\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Para clasificación\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Función de filtro de caracteristicas - stadis. scores\n",
        "def select_kbest_classification(X,y,score_f,k):\n",
        "    sel_kb = SelectKBest(score_func=score_f, k=k)\n",
        "    sel_kb.fit(X,y)\n",
        "    new_cols = sel_kb.get_support()\n",
        "    print(\"Scores:\\n\", sel_kb.scores_, \"\\nP-values:\\n\", sel_kb.pvalues_)\n",
        "    return new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener columnas seleciconadas - (5 caracteristicas)\n",
        "X_new_class = select_kbest_classification(X_class, y_class, f_classif, 5)\n",
        "# Nuevo conjunto de datos\n",
        "df_classification_new = X_class.iloc[:,X_new_class]\n",
        "df_classification_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FH3ND8KGC-4",
        "outputId": "3b890ad5-c878-4e40-b42f-6c06fd920531"
      },
      "outputs": [],
      "source": [
        "# Para regresión\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Lectura de datos\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "columns_drop = [\"Longitude\", \"Latitude\"]\n",
        "\n",
        "X_reg = housing.data.drop(columns=columns_drop)\n",
        "y_reg = housing.target\n",
        "\n",
        "print(\"Feature data dimension: \", X_reg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "dK1yHbhPGywd",
        "outputId": "9a3553a5-8957-4f3d-9ff1-20604c3fd4d2"
      },
      "outputs": [],
      "source": [
        "X_reg.head(3)\n",
        "#y_reg.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "CfaDTQWQoijP"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression,r_regression\n",
        "\n",
        "# Función de filtro de caracteristicas - stadis. scores\n",
        "def select_kbest_regression(X,y,score_f,k):\n",
        "    sel_kb = SelectKBest(score_func=score_f, k=k)\n",
        "    sel_kb.fit(X,y)\n",
        "    new_cols = sel_kb.get_support()\n",
        "    #print(\"Scores:\\n\", sel_kb.scores_, \"\\nP-values:\\n\", sel_kb.pvalues_)\n",
        "    print(\"Scores:\\n\", sel_kb.scores_)\n",
        "    return new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "jU-hFXL9tFZe",
        "outputId": "d212fa2b-cf73-4744-e7e2-fcdd38467df7"
      },
      "outputs": [],
      "source": [
        "# Obtener columnas seleciconadas - (3 caracteristicas)\n",
        "X_new_reg = select_kbest_regression(X_reg, y_reg, f_regression, 3)\n",
        "# Nuevo conjunto de datos\n",
        "df_regression_new = X_reg.iloc[:,X_new_reg]\n",
        "df_regression_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener columnas seleciconadas - (3 caracteristicas)\n",
        "X_new_reg = select_kbest_regression(X_reg, y_reg, r_regression, 3)\n",
        "# Nuevo conjunto de datos\n",
        "df_regression_new = X_reg.iloc[:,X_new_reg]\n",
        "df_regression_new.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuS-C9sZ4vU8"
      },
      "source": [
        "## Métodos Wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNy8i6ulFkMB"
      },
      "source": [
        "### RFE\n",
        "\n",
        "Dado un estimador externo que asigna pesos a las características (p. ej., los coeficientes de un modelo lineal), el objetivo de la eliminación recursiva de características (RFE) es seleccionar características considerando recursivamente conjuntos de características cada vez más pequeños.\n",
        "\n",
        "Primero, el estimador se entrena en el conjunto inicial de características y la importancia de cada característica se obtiene a través de cualquier atributo específico o llamable. Luego, las características menos importantes se eliminan del conjunto actual de características. Ese procedimiento se repite recursivamente en el conjunto podado hasta que finalmente se alcanza el número deseado de características para seleccionar.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Hx_8uI0IFjxV"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "\n",
        "# Función recursiva de selección de características\n",
        "def recursive_feature_selection(X,y,model,k):\n",
        "  rfe = RFE(model, n_features_to_select=k, step=1)\n",
        "  fit = rfe.fit(X, y)\n",
        "  X_new = fit.support_\n",
        "  print(\"Num Features: %s\" % (fit.n_features_))\n",
        "  print(\"Selected Features: %s\" % (fit.support_))\n",
        "  print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
        "\n",
        "  return X_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Para clasificación\n",
        "\n",
        "# Establecer Estimador\n",
        "model = LogisticRegression(max_iter=300)\n",
        "# Obtener columnas seleciconadas - (3 caracteristicas)\n",
        "X_new_class = recursive_feature_selection(X_class, y_class, model, 5)\n",
        "# Nuevo conjunto de datos\n",
        "df_classification_new = X_class.iloc[:,X_new_class]\n",
        "df_classification_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "A7OB8Z5d0UUa",
        "outputId": "9f541858-2103-45e4-fd76-e7fdd59f3f7f"
      },
      "outputs": [],
      "source": [
        "# Para regresión\n",
        "\n",
        "# Establecer Estimador\n",
        "model = LinearRegression()\n",
        "# Obtener columnas seleciconadas - (3 caracteristicas)\n",
        "X_new_reg = recursive_feature_selection(X_reg, y_reg, model, 3)\n",
        "# Nuevo conjunto de datos\n",
        "df_regression_new = X_reg.iloc[:,X_new_reg]\n",
        "df_regression_new.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g292ZmdORCQv"
      },
      "source": [
        "### SequentialFeatureSelector\n",
        "\n",
        "Este selector secuencial de carcaterisicas agrega (selección hacia adelante) o elimina (selección hacia atrás) caracteristicas para formar un subconjunto de caracteristicas de manera codiciosa.\n",
        "\n",
        "En cada etapa, este estimador elige la mejor característica para agregar o eliminar en función de la puntuación de validación cruzada de un estimador.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "# Selector secuencias utilizando regresión logistica - clasificación\n",
        "sfs = SequentialFeatureSelector(LogisticRegression(),\n",
        "                                n_features_to_select=5,\n",
        "                                direction= \"forward\",\n",
        "                                scoring='f1')\n",
        "\n",
        "# Obtener variable seleccionadas\n",
        "sfs = sfs.fit(X_class, y_class)\n",
        "X_new_class = sfs.support_\n",
        "df_classification_new = X_class.iloc[:,X_new_class]\n",
        "df_classification_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ig0AqKxj50FK",
        "outputId": "537408b3-fa08-4fd1-b5e2-97180ef504a3"
      },
      "outputs": [],
      "source": [
        "# Selector secuencias utilizando regresión lineal - Regresión\n",
        "sfs = SequentialFeatureSelector(LinearRegression(),\n",
        "                                n_features_to_select=3,\n",
        "                                direction= \"forward\",\n",
        "                                scoring='r2')\n",
        "\n",
        "# Obtener variable seleccionadas\n",
        "sfs = sfs.fit(X_reg, y_reg)\n",
        "X_new_reg = sfs.support_\n",
        "df_regression_new = X_reg.iloc[:,X_new_reg]\n",
        "df_regression_new.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_ad9j3P9AhA"
      },
      "source": [
        "## Métodos integrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqO-USlHSTvY"
      },
      "source": [
        "### SelectFromModel\n",
        "\n",
        "Meta-transformador para seleccionar características basadas en pesos de importancia.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "l7yHACjhSlw9",
        "outputId": "2d1905ed-7929-4f4e-d81d-7d8a23021834"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Estandarizar los datos\n",
        "standard_scaler = StandardScaler()\n",
        "X_reg_std = standard_scaler.fit_transform(X_reg)\n",
        "y_reg_std = standard_scaler.fit_transform(np.array(y_reg).reshape(-1, 1))\n",
        "\n",
        "# Selector de variables con Lasso\n",
        "sel_ = SelectFromModel(Lasso(alpha=0.03), max_features=4)\n",
        "sel_.fit(X_reg_std, y_reg_std)\n",
        "print(sel_.estimator_.coef_)\n",
        "#Obtener variables seleccionadas\n",
        "X_new_reg = sel_.get_support()\n",
        "\n",
        "df_regression_new = X_reg.iloc[:,X_new_reg]\n",
        "df_regression_new.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjf4QF3B9pwh"
      },
      "source": [
        "# Esquema de validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6DN1oFNq7i3"
      },
      "source": [
        "### Cross Validation\n",
        "\n",
        "Permite evaluar las métricas de desempeño de un modelo mediante validación cruzada y también registra los tiempos de entrenamiento/puntuación.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "b0bm8qFeqw_7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import  cross_validate\n",
        "\n",
        "def cross_validation(model, _X, _y, _cv=5, scoring='f1'):\n",
        "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "      results = cross_validate(estimator=model,\n",
        "                               X=_X,\n",
        "                               y=_y,\n",
        "                               cv=_cv,\n",
        "                               scoring=_scoring,\n",
        "                               return_train_score=True)\n",
        "\n",
        "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
        "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
        "              \"Training Precision scores\": results['train_precision'],\n",
        "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
        "              \"Training Recall scores\": results['train_recall'],\n",
        "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
        "              \"Training F1 scores\": results['train_f1'],\n",
        "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
        "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
        "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
        "              \"Validation Precision scores\": results['test_precision'],\n",
        "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
        "              \"Validation Recall scores\": results['test_recall'],\n",
        "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
        "              \"Validation F1 scores\": results['test_f1'],\n",
        "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdkEkbjzsIJu",
        "outputId": "94800c4c-118b-4e4e-aa67-70818b7a9b7e"
      },
      "outputs": [],
      "source": [
        "# Modelo de regresión logística\n",
        "log_model = LogisticRegression(class_weight=\"balanced\", random_state=0, max_iter=300)\n",
        "# Evaluación del modelo 2\n",
        "log_model_2_result = cross_validation(log_model, X_class, y_class, 10)\n",
        "print(\"Mean Training F1 Score: \", log_model_2_result['Mean Training F1 Score'],\n",
        "      \"\\nMean Validation F1 Score: \", log_model_2_result['Mean Validation F1 Score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf1g8aLUyfdV",
        "outputId": "43fe6f26-d1f5-417e-842a-48873f6408f8"
      },
      "outputs": [],
      "source": [
        "# Otra alternativa utilizando LogisticRegressionCV\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "# Definición de modelo y ajuste a todos los datos\n",
        "clf = LogisticRegressionCV(cv=10, random_state=0, class_weight=\"balanced\", scoring='f1', max_iter=300).fit(X_class, y_class)\n",
        "\n",
        "print(\"Score: \", clf.score(X_class, y_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n31JcMFu1eVl"
      },
      "source": [
        "### LeaveOneOut Cross-Validation\n",
        "\n",
        "Proporciona índices de entrenamiento/prueba para dividir datos en conjuntos de entrenamiento/prueba. Cada muestra se usa una vez como conjunto de prueba (singleton) mientras que las muestras restantes forman el conjunto de entrenamiento.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_class = X_class.values\n",
        "y_class = y_class.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f30NTHFq1enO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create loocv procedure\n",
        "cv = LeaveOneOut()\n",
        "\n",
        "# Listas de valores predichos y valores reales\n",
        "y_true, y_pred = list(), list()\n",
        "\n",
        "for train_ix, test_ix in cv.split(X_class):\n",
        "  # split data\n",
        "  X_train, X_test = X_class[train_ix, :], X_class[test_ix, :]\n",
        "  y_train, y_test = y_class[train_ix], y_class[test_ix]\n",
        "  # fit model\n",
        "  model_log_3 = LogisticRegression(class_weight=\"balanced\", random_state=0, max_iter=1000)\n",
        "  model_log_3.fit(X_train, y_train)\n",
        "  # evaluate model\n",
        "  yhat = model_log_3.predict(X_test)\n",
        "  # store\n",
        "  y_true.append(y_test[0])\n",
        "  y_pred.append(yhat[0])\n",
        "\n",
        "# Metricas de evaluación\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print('Accuracy: %.3f' % acc)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print('F1 score: %.3f' % f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
